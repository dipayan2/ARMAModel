{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e53d823b-64c2-4066-b8e8-153de198a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Headers for the analysis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import skfuzzy as fuzz\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611b9d7-a78b-4d23-a5de-f919ec8f4044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "281f2c69-616b-487b-b40e-ca9c14cedaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filler functions\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(mean_squared_error(targets, predictions))#, squared=False)\n",
    "# Fixed values for the device, not going to change based on our requirement\n",
    "\n",
    "freq_dict = {}\n",
    "freq_dict['gFreq'] = [177000000,266000000,350000000,420000000,480000000,600000000]\n",
    "freq_dict['mFreq'] = [165000000,206000000,275000000,413000000,543000000,633000000,728000000,825000000]#,933000000]\n",
    "freq_dict['sFreq'] = [200000,300000,400000,500000,600000,700000,800000,900000,1000000,1100000,1200000,1300000,1400000]\n",
    "freq_dict['bFreq'] = [200000,300000,400000,500000,600000,700000,800000,900000,1000000,1100000,1200000,1300000,1400000,1500000,1600000,1700000,1800000,1900000,2000000]\n",
    "# cost_list =['cCost','mCost','gCost']\n",
    "cFreq = 'bFreq'\n",
    "mFreq = 'mFreq'\n",
    "gFreq = 'gFreq'\n",
    "\n",
    "cost2FMap = {}\n",
    "cost2FMap['cCost'] = 'bFreq'\n",
    "cost2FMap['mCost'] = 'mFreq'\n",
    "cost2FMap['gCost'] = 'gFreq'\n",
    "\n",
    "## Function to extract the files and send a dataframe\n",
    "\n",
    "def extractDatafromFile(fileName='./UtilTestFinal',padding=1): ## Generally make the padding 1\n",
    "    new_data = pd.read_csv(fileName)\n",
    "    #### This part needs to be \n",
    "    if padding == 0:  # if there is not \n",
    "        new_data['cCost'] =  new_data['bUtil']*new_data['bFreq']/2000000\n",
    "        new_data['mCost'] = new_data['mUtil']*new_data['mFreq']/825000000\n",
    "        new_data['gCost'] = 0\n",
    "        new_data['gFreq'] = 600000000\n",
    "\n",
    "    return new_data\n",
    "\n",
    "#extractDatafromFile()\n",
    "# Getting the exog list for analysis\n",
    "\n",
    "def getExog(endog='cCost'):\n",
    "    cost_list =['cCost','mCost','gCost']\n",
    "    if endog not in cost_list:\n",
    "        print(\"Incorrect Value\")\n",
    "        return None,None\n",
    "    else:\n",
    "        my_list = []\n",
    "        for res in cost_list:\n",
    "            if res != endog:\n",
    "                my_list.append(res)\n",
    "        return my_list[0],my_list[1]\n",
    "\n",
    "# getExog('gCost')\n",
    "\n",
    "## Function to shift the data, enabling testing and trainig\n",
    "\n",
    "def createRequiredDataSet(input_df,endog,shiftAR,shiftARX):\n",
    "    modified_df = pd.DataFrame()\n",
    "    ## Get the exog values\n",
    "    exog,exog1 = getExog(endog)\n",
    "    modified_df = input_df[[endog,exog,exog1]]\n",
    "    # Shifting the endog data\n",
    "    for i in range(1,shiftAR+1):\n",
    "        modified_df['%s_%d'%(endog,i)] = modified_df[endog].shift(i)\n",
    "\n",
    "    # Shifting the exog and exog1 data\n",
    "    modified_df[exog] = modified_df[exog].shift(1)\n",
    "    modified_df[exog1] = modified_df[exog1].shift(1)\n",
    "\n",
    "    for i in range(1,shiftARX+1):\n",
    "        modified_df['%s_%d'%(exog,i)] = modified_df[exog].shift(i+1)\n",
    "        modified_df['%s_%d'%(exog1,i)] = modified_df[exog1].shift(i+1)\n",
    "\n",
    "    # Adding the frequency stuff\n",
    "    modified_df[cFreq] = input_df[cFreq] \n",
    "    modified_df[mFreq] = input_df[mFreq] \n",
    "    modified_df[gFreq] = input_df[gFreq] \n",
    "    modified_df = modified_df.dropna()\n",
    "    return modified_df\n",
    "\n",
    "\n",
    "## Test_train divide\n",
    "\n",
    "def test_train_split(input_df,trainIDX,testIDX,perc=0.8):\n",
    "    totalLen = len(input_df)\n",
    "    if trainIDX == -1 or testIDX == -1:\n",
    "        trainIDX = int(perc*totalLen)\n",
    "        testIDX = int(perc*totalLen)\n",
    "    train_df = input_df.iloc[:trainIDX,:]\n",
    "    test_df = input_df.iloc[testIDX:,:]\n",
    "    return train_df,test_df\n",
    "\n",
    "\n",
    "## get the matrices for training, we are assuming that 0 is the y value and the rest are x, we can choose to skip few columns\n",
    "\n",
    "def getYXData(input_df,ignoreCols=0):\n",
    "    totalLen = len(input_df.columns)\n",
    "    y_data = input_df.iloc[:,0].to_numpy()\n",
    "    x_data = input_df.iloc[:,1:totalLen-ignoreCols].to_numpy()\n",
    "    return y_data,x_data\n",
    "\n",
    "\n",
    "def train_Cluster(data, n_cluster = 5):\n",
    "    # print(\"The stats of the training data: features {} and size {}\".format(len(data[0]), len(data)))\n",
    "    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(data.T, n_cluster, 2, error=0.005, maxiter=1000, init=None, seed = 0)\n",
    "    # print(\"The centroid values are \\n {}\".format(cntr))\n",
    "    return cntr,u\n",
    "\n",
    "\n",
    "def simple_train(yData, xData, weight=None):\n",
    "    if weight is None:\n",
    "        weight = np.ones(len(yData))\n",
    "\n",
    "    new_x = sm.add_constant(xData)\n",
    "    model = sm.WLS(yData,new_x,weights=weight)\n",
    "    result = model.fit()\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def simple_test_single(model, xData):\n",
    "    newX = [1.0]\n",
    "    newX.extend(xData)\n",
    "    y_pred = model.get_prediction(newX).predicted_mean\n",
    "    return y_pred\n",
    "\n",
    "def getSingleCluster(data, cntr):\n",
    "    ut,u0t,dt,jmt,pt,fpct = fuzz.cluster.cmeans_predict(np.array([data]).T,cntr,2,error=0.005,maxiter=1000,init=None,seed=0)\n",
    "    return ut\n",
    "\n",
    "\n",
    "def prediction(model,x,cluster):\n",
    "    ## get cluster\n",
    "    N_CLUST = len(model)\n",
    "    prob_d = getSingleCluster(x,cluster).T[0]\n",
    "    y = []\n",
    "    for i in range(N_CLUST):\n",
    "        ys = simple_test_single(model[i],x)\n",
    "        y.append(ys*prob_d[i])\n",
    "    my_pred = min(sum(y)[0],100.0)\n",
    "    return my_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2f8457b6-36c3-491a-9cd0-6bb62732c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# my_test = extractDatafromFile('./UtilTestFinal',0)\n",
    "# Mod = createRequiredDataSet(my_test,'cCost',5,3)   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "28d1cb99-8045-401d-b6b6-7b0422cb11bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([206000000, 275000000, 165000000, 165000000, 413000000, 165000000,\n",
       "       165000000, 165000000, 275000000, 206000000, 206000000, 275000000,\n",
       "       275000000, 206000000, 275000000, 165000000, 165000000, 413000000,\n",
       "       165000000, 275000000, 275000000, 206000000, 275000000, 275000000,\n",
       "       275000000, 206000000, 206000000, 275000000, 206000000, 206000000,\n",
       "       275000000, 275000000, 206000000, 206000000, 275000000, 275000000,\n",
       "       206000000, 206000000, 275000000, 275000000, 543000000, 165000000,\n",
       "       165000000, 413000000, 413000000, 165000000, 275000000, 206000000,\n",
       "       206000000, 275000000])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_CLUST=5\n",
    "TEST_LEN = 50\n",
    "endog = 'mCost'\n",
    "my_test = extractDatafromFile('./UtilTestFinal',0)\n",
    "Mod = createRequiredDataSet(my_test,endog='cCost',shiftAR=5,shiftARX=3)\n",
    "train_df,test_df = test_train_split(Mod,trainIDX=5000,testIDX=5000,perc=0.0)\n",
    "y_train,x_train = getYXData(train_df,ignoreCols=3)\n",
    "y_test,x_test = getYXData(test_df,ignoreCols=3)\n",
    "### Get the clusters\n",
    "cluster_center,prob = train_Cluster(x_train[:,:],n_cluster = N_CLUST)\n",
    "### Train the models\n",
    "model = []\n",
    "for i in range(N_CLUST):\n",
    "    out_model = simple_train(y_train,x_train,weight = prob[i,:])\n",
    "    model.append(out_model)\n",
    "\n",
    "## Predict the values\n",
    "ys_target = []\n",
    "for id in range(TEST_LEN):\n",
    "    predVal = prediction(model,x_test[id],cluster_center)\n",
    "    ys_target.append(predVal)\n",
    "\n",
    "ys_freq = test_df[cost2FMap[endog]].to_numpy()[:TEST_LEN]\n",
    "ys_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f6fcc91e-d8a7-414d-9d27-1adba23ecfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelPipeline(fileName,endog='cCost',N_CLUST=5,shiftAR=5,shiftARX=3,trainIDX=5000,testIDX=5000,TEST_LEN = 50, energy=True):\n",
    "    my_test = extractDatafromFile(fileName,0) # set to 1 for most of the data, unless no GPU present\n",
    "    Mod = createRequiredDataSet(my_test,endog,shiftAR,shiftARX)\n",
    "    train_df,test_df = test_train_split(Mod,trainIDX,testIDX,perc=0.0)\n",
    "    y_train,x_train = getYXData(train_df,ignoreCols=3)\n",
    "    y_test,x_test = getYXData(test_df,ignoreCols=3)\n",
    "    ### Get the clusters\n",
    "    cluster_center,prob = train_Cluster(x_train[:,:],n_cluster = N_CLUST)\n",
    "    ### Train the Model\n",
    "    model = []\n",
    "    for i in range(N_CLUST):\n",
    "        out_model = simple_train(y_train,x_train,weight = prob[i,:])\n",
    "        model.append(out_model)\n",
    "\n",
    "    ### Test the models\n",
    "    ys_actual = y_test[:TEST_LEN]\n",
    "    ys_est = []\n",
    "    for id in range(TEST_LEN):\n",
    "        predVal = prediction(model,x_test[id],cluster_center)\n",
    "        ys_est.append(predVal)\n",
    "    # print(cost2FMap[endog])        \n",
    "    if energy:\n",
    "        ys_freq = test_df[cost2FMap[endog]].to_numpy()[:TEST_LEN] # the actual frequency we observed\n",
    "        \n",
    "    ##\n",
    "    \n",
    "    return ys_est,ys_actual,rmse(ys_est,ys_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "cedace42-5de0-4c13-a387-06b6bfae8283",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_est,y_act,err = ModelPipeline('./UtilTestFinal','mCost',N_CLUST=3,shiftAR=20,shiftARX=3,trainIDX=5000,testIDX=5000,TEST_LEN = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5a2c8c0b-eaa7-4b90-b6cf-2784852b57d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3926820928647231"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cd6a723e-1f5b-44ea-8abe-dc87192695f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#AR  3  RMSE : 16.36270071265466\n",
      "#AR  4  RMSE : 15.906601209119556\n",
      "#AR  5  RMSE : 15.618240552014347\n",
      "#AR  6  RMSE : 15.541488693273728\n",
      "#AR  7  RMSE : 15.398540020277032\n",
      "#AR  8  RMSE : 15.378594183559889\n",
      "#AR  9  RMSE : 15.371845259005767\n",
      "#AR  10  RMSE : 15.36300572546293\n",
      "#AR  11  RMSE : 15.36512330063981\n",
      "#AR  12  RMSE : 15.585806468788252\n",
      "#AR  13  RMSE : 15.564586188566665\n",
      "#AR  14  RMSE : 15.702221794697364\n",
      "#AR  15  RMSE : 15.72287160818384\n",
      "#AR  16  RMSE : 15.754728981851745\n",
      "#AR  17  RMSE : 15.743832026481673\n",
      "#AR  18  RMSE : 15.663522646487932\n",
      "#AR  19  RMSE : 15.612837402410577\n"
     ]
    }
   ],
   "source": [
    "for ar in range(3,20):\n",
    "    y_est,y_act,err = ModelPipeline('./UtilTestFinal','cCost',N_CLUST=10,shiftAR=ar,shiftARX=ar-2,trainIDX=7000,testIDX=3000,TEST_LEN = 500)\n",
    "    print(\"#AR \",ar,\" RMSE :\", err)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c5f335-1495-4081-bbb4-5de8cc4417b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
