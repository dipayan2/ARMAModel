{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_predict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skfda\n",
    "from skfda.ml.clustering import FuzzyCMeans, KMeans\n",
    "class OSLFuzzyCluster:\n",
    "    def __init__(self,data,n_cluster=3,init_cluster=None,fuzzifier=2):\n",
    "        self.data = data\n",
    "        self.nclust = n_cluster\n",
    "        self.init_clust = init_cluster\n",
    "        self.model = None\n",
    "        self.predictClus = None\n",
    "        self.fData = None\n",
    "        self.fuzzifier=fuzzifier\n",
    "        self.probCond = None\n",
    "    \n",
    "    def getFDataGrid(self, inp):\n",
    "        inp = np.array(inp)\n",
    "        n_dim = inp.ndim\n",
    "        if n_dim == 1:\n",
    "            grid_point = list(range(len(inp)))\n",
    "            data_grid = []\n",
    "            data_grid.append(inp)\n",
    "            fd = skfda.FDataGrid(data_grid,grid_point)\n",
    "            return fd\n",
    "        elif n_dim == 2:\n",
    "            grid_point = list(range(len(inp[0])))\n",
    "            data_grid = []\n",
    "            for i in range(len(inp)):\n",
    "                data_grid.append(inp[i])\n",
    "\n",
    "            fd = skfda.FDataGrid(data_grid,grid_point)\n",
    "            return fd\n",
    "        else:\n",
    "            raise Exception(\"Cannot handle more than 2 dimension for now\") \n",
    "            return None\n",
    "    \n",
    "    def update_data(self,data):\n",
    "        self.data = np.append(self.data,np.array(data))\n",
    "        return\n",
    "        \n",
    "        \n",
    "    def fit(self):    \n",
    "        self.fData = self.getFDataGrid(self.data)\n",
    "        if self.fData == None:\n",
    "            print(\"No data to cluster\")\n",
    "            return None\n",
    "        self.model = FuzzyCMeans(n_clusters=self.nclust,n_init=5 ,init=self.init_clust,fuzzifier=self.fuzzifier,max_iter=400,random_state=0)\n",
    "        self.model.fit(self.fData)\n",
    "        self.predictClus = self.model.predict_proba(self.fData)\n",
    "        return self.model,self.predictClus\n",
    "    \n",
    "    def predict_clust(self,data):\n",
    "        fd = self.getFDataGrid(data)\n",
    "        return self.model.predict_proba(fd)\n",
    "    \n",
    "    def get_center(self):\n",
    "        return self.model.cluster_centers_.data_matrix\n",
    "        \n",
    "    def get_CondProb(self):\n",
    "        prob_count = self.predictClus\n",
    "        n_cluster = self.nclust\n",
    "\n",
    "        PCount = [0 for _ in range(n_cluster)]\n",
    "        PTP_count = [[0 for _ in range(n_cluster)] for _ in range(n_cluster)]\n",
    "        for i in range(len(prob_count)):\n",
    "            for c in range(n_cluster):\n",
    "                PCount[c] += prob_count[i][c]\n",
    "                if i>0:\n",
    "                    for cn in range(n_cluster):\n",
    "                        PTP_count[cn][c] += prob_count[i-1][cn]*prob_count[i][c]\n",
    "\n",
    "\n",
    "        self.probCond = [[0 for _ in range(n_cluster)] for _ in range(n_cluster)]\n",
    "        for i in range(n_cluster):\n",
    "            for j in range(n_cluster):\n",
    "                self.probCond[i][j] = round(PTP_count[i][j]/PCount[i],3) # P(Y(t) in j / Y(t-1) in i)\n",
    "        return self.probCond\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSLARMA:\n",
    "    def __init__(self,endog,p=3,exog=None,weight=None):\n",
    "        self.endog = endog\n",
    "        self.p = p\n",
    "        self.exog = exog\n",
    "        self.w = weight\n",
    "        self.model = None\n",
    "        self.xData = None\n",
    "        self.yData = None\n",
    "        self.ylast = None\n",
    "        self.fitData = None\n",
    "    \n",
    "    def summary(self):\n",
    "        return self.model.summary()\n",
    "        \n",
    "    def getShifted_Dataset(self):\n",
    "        # Currently accepting only one dimensional exog if any\n",
    "        if self.p < 1:\n",
    "            print('Error needs atleast 1')\n",
    "            return None\n",
    "        plen = self.p\n",
    "        df_temp = pd.DataFrame()\n",
    "        df_temp['endog'] = self.endog\n",
    "        # Getting shifted dataset\n",
    "        for i in range(1,self.p+1):\n",
    "            df_temp['Shift_endog_%d' % i] = df_temp['endog'].shift(i)\n",
    "        if self.exog is not None:\n",
    "            df_temp['exog'] = self.exog\n",
    "            plen += 1\n",
    "        if self.w is not None:\n",
    "            df_temp['Weight'] = self.w\n",
    "        elif self.w is None:\n",
    "            df_temp['Weight'] = np.ones(self.endog.shape[0])\n",
    "\n",
    "        df_train_2 = df_temp.dropna()\n",
    "        X_train = df_train_2.iloc[:,1:plen+1].values.reshape(-1,plen)\n",
    "        y_train = df_train_2.iloc[:,0].values.reshape(-1,1)\n",
    "        sample_weight = df_train_2['Weight'].values\n",
    "        X_last = df_train_2.iloc[-1,:self.p].values.reshape(-1,self.p)\n",
    "        return [y_train,X_train,X_last[0],sample_weight]\n",
    "    \n",
    "    def update_data(self,endog,exog=None,weight=None):\n",
    "        # Addpending the data\n",
    "        self.endog = np.concatenate((self.endog,np.array(endog)))\n",
    "        \n",
    "        if exog is not None:\n",
    "            self.exog = np.concatenate((self.exog, np.array(exog)))\n",
    "        if weight is not None:\n",
    "            self.w = np.concatenate((self.w,np.array(weight)))\n",
    "        # This part is helps adding the new observed data and can be used to retrain the model\n",
    "        self.ylast = self.endog[-1:-(self.p+1):-1]\n",
    "#         #Test Code\n",
    "#         print(\"Update\",self.ylast)\n",
    "#         #End testcode\n",
    "        return\n",
    "    \n",
    "    def WeighedLearn(self,y,X,weight):\n",
    "        import statsmodels.api as sm\n",
    "        X_sm = sm.add_constant(X)\n",
    "        model = sm.WLS(y,X_sm,weights=weight)\n",
    "        result = model.fit()\n",
    "        return result\n",
    "    \n",
    "    def fit(self):\n",
    "        tData = self.getShifted_Dataset()\n",
    "#         self.yData = tData[0]\n",
    "#         self.xData = tData[1]\n",
    "        self.ylast = tData[2]\n",
    "#         weight = tData[3]\n",
    "        self.model = self.WeighedLearn(tData[0],tData[1],weight=tData[3])\n",
    "        return self.model,self.ylast\n",
    "           \n",
    "    def get_predict(self,steps=1,exog=None):\n",
    "        # Ensure that the exog and model have the same dimension. Currently we have only one dim of exog\n",
    "        if exog is not None:\n",
    "            #Update\n",
    "            if len(exog) != steps:\n",
    "                print(\"Exog variable incorrect\")\n",
    "                return None\n",
    "        # Assume exog is there\n",
    "        Y_out = []\n",
    "#         print(\"exog\",exog)\n",
    "        if exog is not None:\n",
    "            X_update = []        \n",
    "            X_inp = self.ylast\n",
    "#             print(\"ylast\",self.ylast)\n",
    "            for i in range(steps):\n",
    "                X_test = [1.0]\n",
    "                X_test.extend(X_inp)\n",
    "                X_test.append(exog[i])\n",
    "#                 print(\"Xtest\",X_test)\n",
    "                y_pred = self.model.get_prediction(X_test).predicted_mean\n",
    "                Y_out.extend(y_pred)\n",
    "                X_i = list(y_pred)\n",
    "                X_i.extend(X_inp[:-1])\n",
    "                X_inp = X_i\n",
    "#                 print(X_inp)\n",
    "            # Predict the data\n",
    "            return Y_out\n",
    "        else:\n",
    "            #No exog\n",
    "            X_inp = self.ylast\n",
    "            for i in range(steps):\n",
    "                X_test = [1.0]\n",
    "                X_test.extend(X_inp)\n",
    "                y_pred = self.model.get_prediction(X_test).predicted_mean\n",
    "                Y_out.extend(y_pred)\n",
    "                X_i = list(y_pred)\n",
    "                X_i.extend(X_inp[:-1])\n",
    "                X_inp = X_i\n",
    "    #             print(X_inp)\n",
    "            return Y_out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Modifier Code\n",
    "def getDataFrame(fileName):\n",
    "    myDf = pd.read_csv(fileName)\n",
    "    myDf['memLoad'] = myDf['memUse']*100/myDf['memTot']\n",
    "    myDf['memScore'] = myDf['memLoad']*myDf['memfreq']/825000000\n",
    "    myDf['memF'] = myDf['memfreq']*100/825000000\n",
    "    myDf['cpuScore'] = myDf['cpuload']*myDf['cpufreq']/1400000\n",
    "    myDf['cpuF'] = myDf['cpufreq']*100/1000000\n",
    "    return myDf\n",
    "\n",
    "def getDataMatrix(dx,dy=None):\n",
    "    data_matrix=[]\n",
    "    if dy is None:\n",
    "        for v in dx:\n",
    "            data_matrix.append([round(v,2),round(v,2)])\n",
    "    else:\n",
    "        for v in zip(dx,dy):\n",
    "            data_matrix.append([round(v[0],2),round(v[1],2)])\n",
    "    return data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing without exog\n",
    "def main():\n",
    "    utilData = getDataFrame('./Util_Run1.csv')\n",
    "    dy = utilData.cpuload.diff().dropna().to_numpy()\n",
    "#     dy = utilData.cpuload.dropna().to_numpy()\n",
    "    nCluster = 8\n",
    "    y_train = dy[:2000]\n",
    "    y_test = dy[2000:]\n",
    "    y_dmat = getDataMatrix(y_train)\n",
    "    myClust = OSLFuzzyCluster(y_dmat,n_cluster=nCluster)\n",
    "    _, data_weight = myClust.fit()\n",
    "#     print(dy[0])\n",
    "#     print(data_weight)\n",
    "#     print(\"data_cluster\", myClust.get_center())\n",
    "    trans_prob = myClust.get_CondProb()\n",
    "    print(trans_prob)\n",
    "    print(\"\\n\\n\\n\")\n",
    "    # We will send the weights of the data and then train these models\n",
    "    models = []\n",
    "    # Train the models\n",
    "    for i in range(nCluster):\n",
    "        model = OSLARMA(y_train,p=5,weight=data_weight[:,i])\n",
    "        model.fit()\n",
    "#         print(model.summary())\n",
    "        models.append(model)\n",
    "    \n",
    "    # Models are trained now begin prediction\n",
    "#     print(\"last actual value\", y_train[-1],\"Likelihood cluster\", myClust.predict_clust([ y_train[-1], y_train[-1]]))\n",
    "    y_prior = y_train[-1]\n",
    "    for i in range(100):\n",
    "        # Get prob of P(Y(t-1) in i) using cluster\n",
    "        P_prior = myClust.predict_clust([y_prior,y_prior])[0]\n",
    "#         print(\"P\",P_prior)\n",
    "        P_like = []\n",
    "        # Predict likelihood of Y(t) in cluster based on transition prob\n",
    "        for k in range(nCluster):\n",
    "            prob = 0\n",
    "            for j in range(nCluster):\n",
    "                prob += trans_prob[j][k]*P_prior[j]\n",
    "            P_like.append(prob)\n",
    "        \n",
    "#         print(\"PLike\",P_like)\n",
    "        y_act = y_test[i]\n",
    "        y_prior = y_act\n",
    "        y_pred = []\n",
    "        y_est = 0\n",
    "        for j in range(nCluster):\n",
    "            y_pred.append(models[j].get_predict()[0])\n",
    "            y_est += y_pred[-1]*P_like[j]\n",
    "        \n",
    "        print(i, y_act,y_est)\n",
    "        \n",
    "        for j in range(nCluster):\n",
    "            models[j].update_data([y_act])\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.015, 0.228, 0.008, 0.203, 0.002, 0.257, 0.088, 0.2], [0.078, 0.183, 0.001, 0.271, 0.005, 0.026, 0.224, 0.212], [0.023, 0.03, 0.003, 0.261, 0.418, 0.017, 0.077, 0.172], [0.037, 0.053, 0.007, 0.537, 0.003, 0.011, 0.097, 0.254], [0.011, 0.066, 0.067, 0.638, 0.003, 0.092, 0.033, 0.09], [0.099, 0.081, 0.002, 0.385, 0.004, 0.026, 0.186, 0.215], [0.026, 0.198, 0.003, 0.246, 0.004, 0.063, 0.185, 0.275], [0.049, 0.082, 0.002, 0.504, 0.002, 0.017, 0.143, 0.2]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 -2.0 1.0415960067521912\n",
      "1 2.0 1.1217036726462744\n",
      "2 1.0 0.37894963340185317\n",
      "3 -5.0 0.4087395725407761\n",
      "4 4.0 1.3110553566856686\n",
      "5 0.0 -0.10123778471932832\n",
      "6 0.0 0.45716543667609333\n",
      "7 1.0 0.4848592118002448\n",
      "8 -1.0 0.37294826756968447\n",
      "9 -2.0 0.6617226791944689\n",
      "10 1.0 1.0512147820963051\n",
      "11 1.0 0.4878337374885504\n",
      "12 2.0 0.4360844331715237\n",
      "13 -5.0 0.27819549017424827\n",
      "14 1.0 1.2826588460450496\n",
      "15 0.0 0.5047543965869822\n",
      "16 1.0 0.559418367522009\n",
      "17 -2.0 0.46367420014633354\n",
      "18 2.0 1.0017269538206768\n",
      "19 1.0 0.3300953832579516\n",
      "20 0.0 0.3663537098479578\n",
      "21 0.0 0.4435210956666189\n",
      "22 -2.0 0.4583283523456164\n",
      "23 1.0 1.0279231102055242\n",
      "24 2.0 0.4704194148792529\n",
      "25 -2.0 0.3119209736844347\n",
      "26 1.0 0.9550737281739489\n",
      "27 -1.0 0.42390650476050284\n",
      "28 3.0 0.7041206675698769\n",
      "29 -2.0 0.11433949327388282\n",
      "30 -1.0 0.9472547121892709\n",
      "31 0.0 0.7278485480937152\n",
      "32 1.0 0.5500506529295301\n",
      "33 37.0 0.4456194078377195\n",
      "34 -14.0 -10.231096850399286\n",
      "35 -5.0 0.920516538329747\n",
      "36 -18.0 1.0442057788892865\n",
      "37 -1.0 3.641570643297263\n",
      "38 6.0 1.4983979809060548\n",
      "39 -5.0 -0.5811662809242875\n",
      "40 4.0 1.275843224416923\n",
      "41 -6.0 -0.05903101617300355\n",
      "42 3.0 1.3664452684304706\n",
      "43 93.0 0.23766702412692364\n",
      "44 0.0 -15.299014827760507\n",
      "45 0.0 -2.983563517005081\n",
      "46 0.0 -2.0922412325072623\n",
      "47 0.0 -1.3727868715796516\n",
      "48 0.0 -0.3915162052582152\n",
      "49 0.0 0.5067350467253153\n",
      "50 0.0 0.5067350467253153\n",
      "51 0.0 0.5067350467253153\n",
      "52 0.0 0.5067350467253153\n",
      "53 0.0 0.5067350467253153\n",
      "54 -2.0 0.5067350467253153\n",
      "55 2.0 1.0381062129622665\n",
      "56 -6.0 0.36831831964372974\n",
      "57 -2.0 1.4034078253057054\n",
      "58 0.0 1.2258762209532668\n",
      "59 0.0 0.7288141103440469\n",
      "60 8.0 0.6626623564191289\n",
      "61 0.0 -2.314505386774586\n",
      "62 -8.0 0.22607185105031036\n",
      "63 -2.0 1.4366194412362572\n",
      "64 -2.0 1.275416757997247\n",
      "65 2.0 1.2892378236360573\n",
      "66 10.0 0.5877351787178128\n",
      "67 0.0 -2.8438331888309447\n",
      "68 0.0 0.13501896224178278\n",
      "69 0.0 0.20698322927992385\n",
      "70 0.0 0.2884343669550471\n",
      "71 0.0 0.41014889059805393\n",
      "72 0.0 0.5067350467253153\n",
      "73 0.0 0.5067350467253153\n",
      "74 0.0 0.5067350467253153\n",
      "75 0.0 0.5067350467253153\n",
      "76 0.0 0.5067350467253153\n",
      "77 0.0 0.5067350467253153\n",
      "78 0.0 0.5067350467253153\n",
      "79 0.0 0.5067350467253153\n",
      "80 0.0 0.5067350467253153\n",
      "81 0.0 0.5067350467253153\n",
      "82 0.0 0.5067350467253153\n",
      "83 -10.0 0.5067350467253153\n",
      "84 -5.0 1.9657028216394654\n",
      "85 5.0 1.7525887000574814\n",
      "86 10.0 -0.24134335939584928\n",
      "87 0.0 -2.91160616196526\n",
      "88 0.0 0.18820121401847245\n",
      "89 -10.0 0.17626404155465758\n",
      "90 -4.0 1.9549172935090262\n",
      "91 5.0 1.710461655952824\n",
      "92 9.0 -0.2808054231636241\n",
      "93 0.0 -2.749445044740539\n",
      "94 0.0 0.20580042252654795\n",
      "95 0.0 0.19453266183811924\n",
      "96 0.0 0.27935686497135015\n",
      "97 0.0 0.41980750621078\n",
      "98 0.0 0.5067350467253153\n",
      "99 0.0 0.5067350467253153\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
